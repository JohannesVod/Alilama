{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c10939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def visMatr(matrix):\n",
    "    plt.imshow(matrix, cmap='viridis', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.title('Matrix Visualization')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80c1deb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: {'model_name': 'alilama', 'd_model': 128, 'blocks': 8, 'max_seq_len': 128, 'num_heads': 8, 'hidden_dim': 512, 'head_width': 16, 'weight_tying_dict': {}}\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import Transformer, ModelParameters\n",
    "from data.tokenizer import RegexTokenizer\n",
    "\n",
    "models_folder = \"models\"\n",
    "tokenizer_folder = \"data\"\n",
    "model_name = \"alilama_2M\"\n",
    "\n",
    "tok_path = os.path.join(\"data\", \"tokenizer.model\")\n",
    "try:\n",
    "    tokenizer = RegexTokenizer()\n",
    "    tokenizer.load(tok_path)\n",
    "except:\n",
    "    raise RuntimeError(f\"tokenizer not found. Make sure {tok_path} exists\")\n",
    "\n",
    "device = \"cpu\"\n",
    "token_count = len(tokenizer)\n",
    "model_path = os.path.join(models_folder, model_name+\".pth\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    loaded_state = torch.load(model_path, map_location=device)\n",
    "    inpt_params = loaded_state[\"params\"]\n",
    "    params = ModelParameters(**inpt_params)\n",
    "    print(\"parameters:\", inpt_params)\n",
    "    params.max_seq_len = 10000 # increase as seen in ALiBi paper\n",
    "    model = Transformer(token_count=token_count, device=device, params=params)\n",
    "    model.load_state_dict(loaded_state['state_dict'])\n",
    "    print(\"Model loaded successfully.\")\n",
    "else:\n",
    "    print(\"Could not find model!\")\n",
    "\n",
    "def generateStream(size, inpt_tokens=None, temperature=1):\n",
    "    for res in model.genLazy(size, inpt_tokens=inpt_tokens, temperature=temperature):\n",
    "        l = [res[0][-1]]\n",
    "        yield tokenizer.decode(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cf61b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      " He had a big bike with a lot of wheels and a bell. One day, he saw a little girl who was sad. She had lost her toy. Mike wanted to help her. He looked around and saw a little girl. She was holding a toy. Mike was happy to see her toy. He said, \"Hi, I'm Mike. Do you want to play with me?\" The little girl smiled and said, \"Yes, I would love to play with you!\" They played together for a while. Mike and the little girl were very happy. They rode their bikes and rode their bikes. They had so much fun. When it was time to go home, Mike said goodbye to the little girl. He said, \"Thank you for playing with me. I had a great time!\" STARTSTORY Once upon a time, there was a little girl named Lily. She loved to play with her toys and her favorite toy was a teddy bear. One day, Lily's mom asked her to help her with the laundry. Lily was happy to help and started to put the clothes in the washing machine. As she was putting the clothes in the washing machine, she accidentally dropped it on the floor. The clothes went everywhere! Lily was sad and said, \"Mommy, my mommy took my teddy bear!\" Her mom said, \"Don't worry, Lily. We can clean it up together.\" They cleaned the laundry and put the clothes in the washing machine. Lily was happy again and said, \"Thank you, Mommy. You are the best!\" STARTSTORY Once upon a time, there was a little girl named Lily. She loved to play outside in the park. One day, she saw a big, scary dog. The dog was very friendly and Lily wanted to pet it. But her mom said, \"Don't worry, Lily. We can't go play here. The dog is not nice.\" Lily was sad, but she understood.\n"
     ]
    }
   ],
   "source": [
    "# this is the story the model tries to continue:\n",
    "start_story = 'Mike loves to ride on his bike.' # Don't use a trailing space!!!\n",
    "# REASONING TEST (sometimes works). We expect something like \"come down.\":\n",
    "# start_story = 'If i throw a ball into the air, it will eventually'\n",
    "modelInput = \" STARTSTORY \" + start_story\n",
    "temperature = 10 # how deterministic the model decides the next token (0 = random)\n",
    "model.train()\n",
    "as_tens = tokenizer.encode_ordinary(modelInput)\n",
    "print(len(as_tens))\n",
    "as_tens = torch.tensor(as_tens).unsqueeze(0).to(device)\n",
    "for l in generateStream(400, as_tens, temperature=temperature):\n",
    "    print(l, end=\"\")\n",
    "\n",
    "# show attention scores\n",
    "\"\"\"att_scores = model.getAttScores()\n",
    "first_block = att_scores[0]\n",
    "for head in range(first_block.shape[1]):\n",
    "    att = first_block[0,head,:,:].detach().numpy()\n",
    "    visMatr(att)\"\"\"\n",
    "\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
