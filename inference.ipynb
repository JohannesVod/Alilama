{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6c10939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def visMatr(matrix):\n",
    "    plt.imshow(matrix, cmap='viridis', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.title('Matrix Visualization')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "80c1deb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import Transformer, ModelParameters\n",
    "from data.tokenizer import RegexTokenizer\n",
    "\n",
    "models_folder = \"models\"\n",
    "tokenizer_folder = \"data\"\n",
    "model_name = \"alilama_15M\"\n",
    "\n",
    "tok_path = os.path.join(\"data\", \"tokenizer.model\")\n",
    "try:\n",
    "    tokenizer = RegexTokenizer()\n",
    "    tokenizer.load(tok_path)\n",
    "except:\n",
    "    raise RuntimeError(f\"tokenizer not found. Make sure {tok_path} exists\")\n",
    "\n",
    "device = \"cpu\"\n",
    "token_count = len(tokenizer)\n",
    "model_path = os.path.join(models_folder, model_name+\".pth\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    loaded_state = torch.load(model_path, map_location=device)\n",
    "    inpt_params = loaded_state[\"params\"]\n",
    "    params = ModelParameters(**inpt_params)\n",
    "    print(\"parameters:\", inpt_params)\n",
    "    params.max_seq_len = 10000 # increase as seen in ALiBi paper\n",
    "    model = Transformer(token_count=token_count, device=device, params=params)\n",
    "    model.load_state_dict(loaded_state['state_dict'])\n",
    "    print(\"Model loaded successfully.\")\n",
    "else:\n",
    "    print(\"Could not find model!\")\n",
    "\n",
    "def generateStream(size, inpt_tokens=None, temperature=1):\n",
    "    for res in model.genLazy(size, inpt_tokens=inpt_tokens, temperature=temperature):\n",
    "        l = [res[0][-1]]\n",
    "        yield tokenizer.decode(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2cf61b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      " He had a big bike with a lot of wheels and a bell. One day, he saw a little girl who was sad. She had lost her toy. Mike wanted to help her. He asked his mom, \"Mom, have you seen my toy?\" His mom said, \"No, but let's look for it together.\" They looked and looked, but they could not find the toy. Then, Mike had an idea. He said, \"I will help you find your toy.\" They looked everywhere, but they could not find the toy. Mike was sad. Then, Mike had an idea. He said, \"Let's ask our mom for help.\" They went to their mom and asked, \"Mom, can we help you find your toy?\" Her mom smiled and said, \"Yes, we can help you find it.\" They looked and looked, and finally, they found the toy under a big tree. The little girl was so happy! She said, \"Thank you, Mike!\" They all played together and had a fun day. STARTSTORY Once upon a time, there was a little girl named Lily. She loved to play outside in the sunshine. One day, she saw a big, scary dog. The dog was very friendly and Lily wanted to pet it. But her mom said, \"No, Lily. The dog is not nice. We should not go near him.\" Lily was sad, but she understood. She went back to her house and told her mom about the dog. Her mom said, \"Don't worry, Lily. We can go back to the park and play with the dog. But we can't go near the big dog. It's too scary.\" Lily was still scared, but she was also happy to be home. She said, \"Okay, Mom. I will come back and play with you.\" And they went home, happy and safe. STARTSTORY Once upon a time, there was a little girl named Lily\n"
     ]
    }
   ],
   "source": [
    "# this is the story the model tries to continue:\n",
    "start_story = 'Mike loves to ride on his bike.' # Don't use a trailing space!!!\n",
    "# REASONING TEST (sometimes works). We expect something like \"come down.\":\n",
    "# start_story = 'If i throw a ball into the air, it will eventually'\n",
    "modelInput = \" STARTSTORY \" + start_story\n",
    "temperature = 100 # how deterministic the model decides the next token (0 = random)\n",
    "model.train()\n",
    "as_tens = tokenizer.encode_ordinary(modelInput)\n",
    "print(len(as_tens))\n",
    "as_tens = torch.tensor(as_tens).unsqueeze(0).to(device)\n",
    "for l in generateStream(400, as_tens, temperature=temperature):\n",
    "    print(l, end=\"\")\n",
    "\n",
    "# show attention scores\n",
    "\"\"\"att_scores = model.getAttScores()\n",
    "first_block = att_scores[0]\n",
    "for head in range(first_block.shape[1]):\n",
    "    att = first_block[0,head,:,:].detach().numpy()\n",
    "    visMatr(att)\"\"\"\n",
    "\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
