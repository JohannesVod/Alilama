{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80c1deb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import Transformer\n",
    "from tokenizeData import Tokenizer\n",
    "\n",
    "models_folder = \"models\"\n",
    "model_name = \"alilama_26M\"\n",
    "\n",
    "tok_path = os.path.join(models_folder, \"tokenizer.json\")\n",
    "try:\n",
    "    tokenizer = Tokenizer(path=tok_path)\n",
    "except:\n",
    "    raise RuntimeError(f\"tokenizer not found. Make sure {tok_path} exists\")\n",
    "\n",
    "device = \"cpu\"\n",
    "token_count = len(tokenizer)\n",
    "model_path = os.path.join(models_folder, model_name+\".pth\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    loaded_state = torch.load(model_path, map_location=device)\n",
    "    inpt_params = loaded_state[\"params\"]\n",
    "    inpt_params.max_seq_len = 10000 # increase as seen in ALiBi paper\n",
    "    model = Transformer(token_count=token_count, device=device, params=inpt_params)\n",
    "    model.load_state_dict(loaded_state['state_dict'])\n",
    "    print(\"Model loaded successfully.\")\n",
    "\n",
    "def generateStream(size, inpt_tokens=None, temperature=1):\n",
    "    for res in model.genLazy(size, inpt_tokens=inpt_tokens, temperature=temperature):\n",
    "        l = [res[0][-1]]\n",
    "        yield tokenizer.detokenize(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2cf61b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " One day, he saw a big tree with a lot of apples. Tim wanted to eat an apple, but he could not reach the apples.\n",
      "Tim asked his friend, Sam, to help him. Sam said, \"I will help you, Tim.\" Sam was happy to help. He picked the apples and gave them to Tim.\n",
      "Tim and Sam went to the market to buy apples. They bought apples, bananas, and oranges. They were very happy. But then, something unexpected happened. A big wind came and blew the apples away! Tim and Sam were sad.\n",
      "But then, a big bird came and picked up the apples. The bird flew away with the apples. Tim and Sam were"
     ]
    }
   ],
   "source": [
    "# this is the story the model tries to continue:\n",
    "start_story = 'A long time ago there was a boy named Tim. He liked to ride on his bike.'\n",
    "# REASONING TEST (sometimes works). We expect something like \"come down.\":\n",
    "# start_story = 'If i throw a ball into the air, it will eventually'\n",
    "\n",
    "modelInput = \"STARTSTORY \" + start_story\n",
    "temperature = 2 # how deterministic the model decides the next token (0 = random)\n",
    "model.eval()\n",
    "as_tens = tokenizer.tokenize(modelInput, \"Tokenize Data\", use_tqdm=False)\n",
    "as_tens = torch.tensor(as_tens).unsqueeze(0).to(device)\n",
    "for l in generateStream(256, as_tens, temperature=temperature):\n",
    "    print(l, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
